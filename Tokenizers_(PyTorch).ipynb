{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQWmWw7a8_kB"
      },
      "source": [
        "# Tokenizers (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khvAuLzT8_kD"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcX1wyDW8_kE"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0KMMtcW48_kG",
        "outputId": "02ce661c-67ed-49aa-e1d4-d243da08034b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Jim', 'Henson', 'was', 'a', 'puppeteer']\n"
          ]
        }
      ],
      "source": [
        "tokenized_text = \"Jim Henson was a puppeteer\".split()\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка и сохранение"
      ],
      "metadata": {
        "id": "fwkjVjnf9mbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка и сохранение токенизаторов так же просты, как и в случае с моделями: они основаны на тех же двух методах: `from_pretrained()` и `save_pretrained()`. Эти методы загрузят или сохранят алгоритм, используемый токенизатором (немного похоже на архитектуру модели), а также его словарь (немного похоже на веса модели)."
      ],
      "metadata": {
        "id": "Y2L3bxBs9ofC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка токенизатора"
      ],
      "metadata": {
        "id": "2qeTh5V2BIG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка токенизатора BERT, обученного с той же контрольной точкой, что и BERT, выполняется так же, как загрузка модели, за исключением того, что мы используем класс BertTokenizer:"
      ],
      "metadata": {
        "id": "n5M3jTPpBQrx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-7WEnc48_kH"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс AutoTokenizer выберет нужный класс токенизатора в библиотеке на основе имени контрольной точки и т.о., может использоваться напрямую с любой контрольной точкой:"
      ],
      "metadata": {
        "id": "1nPS96H3AXcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "mMd0uX1fArvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сохранение токенизатора"
      ],
      "metadata": {
        "id": "NnQj6qOcA3Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-TS5rj1R_BY4",
        "outputId": "32d386fd-c53c-4b33-bcd0-dafb984ba303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/Hugging_face/tokenizer_dir\""
      ],
      "metadata": {
        "id": "any3vq5v_GeB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h7av9his8_kK",
        "outputId": "b7b40c60-daa9-40de-d29c-de594f1bdef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/Hugging_face/tokenizer_dir/tokenizer_config.json',\n",
              " '/content/drive/My Drive/Hugging_face/tokenizer_dir/special_tokens_map.json',\n",
              " '/content/drive/My Drive/Hugging_face/tokenizer_dir/vocab.txt',\n",
              " '/content/drive/My Drive/Hugging_face/tokenizer_dir/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tokenizer.save_pretrained(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls \"/content/drive/My Drive/Hugging_face/tokenizer_dir\""
      ],
      "metadata": {
        "id": "NGDXo3gz_fBN",
        "outputId": "38035282-643b-431c-f6ab-e6b0ba5c4fcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "special_tokens_map.json  tokenizer_config.json  vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Токенизация"
      ],
      "metadata": {
        "id": "oq7UQghBBuhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MW8eb_j-8_kK",
        "outputId": "cad6c51e-d1ab-4673-df82-91dd43cbdd13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens - ['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n",
            "tokenizer(sequence) - {'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "ids - [7993, 170, 13809, 23763, 2443, 1110, 3014]\n"
          ]
        }
      ],
      "source": [
        "sequence = \"Using a Transformer network is simple\"\n",
        "# Вначаеле идет собственно токкенизация\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "print(f'tokens - {tokens}')\n",
        "# а затем эти токены индексируются в соответствии с индексами соответсвующей им модели\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(f'tokenizer(sequence) - {tokenizer(sequence)}')\n",
        "print(f'ids - {ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m-6CrNj48_kM",
        "outputId": "fd8cbd60-32b7-4f26-83d4-09aa5f313856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Using a transformer network is simple'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
        "decoded_string"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Tokenizers (PyTorch)",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}